{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from nltk import word_tokenize\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "\n",
        "# !pip install nltk\n",
        "\n",
        "\"\"\"\n",
        "This code performs basic text analysis using NLTK library.\n",
        "It tokenizes a given text, calculates the frequency distribution of words,\n",
        "and prints the frequency of a specific word.\n",
        "\n",
        "Steps:\n",
        "1. Install necessary libraries (nltk).\n",
        "2. Download 'punkt' resource from NLTK for tokenization.\n",
        "3. Tokenize the input text into individual words.\n",
        "4. Calculate the frequency distribution of tokens.\n",
        "5. Print the frequency distribution.\n",
        "6. Print the frequency of a specific token ('AI' in this case).\n",
        "\"\"\"\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "text = \"\"\"Artificial intelligence (AI) is rapidly transforming various aspects of our lives.\n",
        "From self-driving cars to personalized recommendations, AI is becoming increasingly\n",
        "integrated into our daily routines. The potential benefits of AI are vast, including\n",
        "improved healthcare, more efficient transportation, and advancements in scientific\n",
        "discovery. However, ethical considerations and potential job displacement are\n",
        "important factors to consider as AI technology continues to evolve.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Calculating the frequency of each token\n",
        "fdist = FreqDist(tokens)\n",
        "\n",
        "# Printing the frequency distribution\n",
        "print(fdist)\n",
        "\n",
        "# If we want we can also access the frequency of individual tokens like this:\n",
        "print(fdist['AI'])  # It will Prints the frequency of the token 'AI'\n",
        "\n",
        "print(\"List of Tokens:\", tokens)  #Print the list of tokens.\n",
        "print(\"Number of Tokens:\", len(tokens))  #Count the number of tokens in the text.\n",
        "\n",
        "#Identify the frequency of each token\n",
        "token_freq = FreqDist(tokens)\n",
        "print(\"\\nToken Frequency:\", token_freq.most_common())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUoZf0gAr-sc",
        "outputId": "03f74354-98c8-4a69-d53e-14506d7f4728"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 55 samples and 73 outcomes>\n",
            "4\n",
            "List of Tokens: ['Artificial', 'intelligence', '(', 'AI', ')', 'is', 'rapidly', 'transforming', 'various', 'aspects', 'of', 'our', 'lives', '.', 'From', 'self-driving', 'cars', 'to', 'personalized', 'recommendations', ',', 'AI', 'is', 'becoming', 'increasingly', 'integrated', 'into', 'our', 'daily', 'routines', '.', 'The', 'potential', 'benefits', 'of', 'AI', 'are', 'vast', ',', 'including', 'improved', 'healthcare', ',', 'more', 'efficient', 'transportation', ',', 'and', 'advancements', 'in', 'scientific', 'discovery', '.', 'However', ',', 'ethical', 'considerations', 'and', 'potential', 'job', 'displacement', 'are', 'important', 'factors', 'to', 'consider', 'as', 'AI', 'technology', 'continues', 'to', 'evolve', '.']\n",
            "Number of Tokens: 73\n",
            "\n",
            "Token Frequency: [(',', 5), ('AI', 4), ('.', 4), ('to', 3), ('is', 2), ('of', 2), ('our', 2), ('potential', 2), ('are', 2), ('and', 2), ('Artificial', 1), ('intelligence', 1), ('(', 1), (')', 1), ('rapidly', 1), ('transforming', 1), ('various', 1), ('aspects', 1), ('lives', 1), ('From', 1), ('self-driving', 1), ('cars', 1), ('personalized', 1), ('recommendations', 1), ('becoming', 1), ('increasingly', 1), ('integrated', 1), ('into', 1), ('daily', 1), ('routines', 1), ('The', 1), ('benefits', 1), ('vast', 1), ('including', 1), ('improved', 1), ('healthcare', 1), ('more', 1), ('efficient', 1), ('transportation', 1), ('advancements', 1), ('in', 1), ('scientific', 1), ('discovery', 1), ('However', 1), ('ethical', 1), ('considerations', 1), ('job', 1), ('displacement', 1), ('important', 1), ('factors', 1), ('consider', 1), ('as', 1), ('technology', 1), ('continues', 1), ('evolve', 1)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w-_c-cmYsRLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}